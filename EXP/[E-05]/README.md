# 회고록
- 파일 설명 : 메인코드와 정확도 최고달성코드를 나눠서 업로드 하였음. ([E-05]가위바위보.ipynb 가 메인 코드)
- 한계점 : np.random.seed를 고정하지 않아서 인지 동일한 데이터,모델에서도 반복적으로 초기화후 훈련/평가를 진행하였을때 전혀다른 수치를 보여주기도 함 (45~66%) 다만 시드 고정을 진행하였을 때 정확도가 모델의 성능을 나타내는가에 대한 우려가 있어 시드고정하지 않고 그대로 진행하였음. 따라서 더 많은 것을 추가하여 실험한 메인코드는 오히려 정확도가 떨어지는 모습을 보여줌.

## 데이터 전처리
- image_size : 기본적인 베이스코드를 최대한 따라가는 방향으로 진행하였음. 그러나 28X28의 사진으로는 모델 레이어를 깊게쌓는데 한계가 있어 acc 66%이 출력된 코드에서는 64x64를, 메인코드에서는 128x128 사이즈의 사진으로 진행하였음.

- x_train_norm : 66%를 달성한 코드에서는 정규화를 안한 이미지로 진행하였을 때 평균적으로 높은 성능을 보여줌...(이유는 아직도 모르겠음..)

- data : 일부 분류하기 어려운 사진 및 전혀 상관없는 이미지 데이터들을 임의로 삭제.

- tf.image.central_crop : 메인코드에서만 진행. 모델의 성능이 크게 흔들리는 이유가 완전히 달라지는 배경에 있다고 생각해서 배경제거 cv2로 실습해보았으나 실력문제로 끝까지 진행하지못하고 포기하게됨. 차선책으로 타겟이 되는 손이 사진에서 최대한 많은 비중을 차지할수있도록 crop을 통해서 잘라냄

## 모델 설정
try1 : 모델의 기본틀은 CNN에서 출발하였음. conv2d - maxpooling을 여러겹으로 쌓을 경우 shape이 빠르게 줄어드는 상황이 발생하였음.channel값을 변경하거나 padding을 씌워보기도 하였으나 유의미한 성능향상은 없었음.

try2 : VGG모델의 일부 모형을 채용해 conv2d-conv2d-maxpooling의 형태로 쌓아봄. 5~10%정도 정확도 향상과 test loss가 줄어드는 모습을 볼 수 있었음. 다만 maxpooling의 경우 1,2개일때보다 3개로 구성하였을때 안정적으로 결과가 출력되는 경향을 볼 수 있었음. 

try3 : 요즘 떠오른다는 활성화함수 gelu를 적용하여 실험을 진행하였음. 학습시에 로스가 빠르게 줄어들면서 안정적인 모습을 보였으나, 정확도면에서는 relu와 큰 차이를 보이지못함.

## 과적합 방지책
1. Dropout : 어떤 블로그에서는 활성화 함수가 작동하는 레이어 뒤에 적용하는 경우가 있었는데, 실험결과 성능이 역으로 하락하는 모습을 보여주어 마지막 Dense layer에 한개만 적용하였음.
2. early stopping + checkPoint : train set 뿐만아니라 validation set에서도 과한 정확도가 나오는 경우가 있어 early stop으로 안정적인 학습을 보여주지못할때 끊어보려함. 그리고 가장 좋은 모습을 보여주었던 epoch에서 모델을 저장하고 test set에 적용하였음.

## 결론
resnet 등의 pretrain된 모델을 적용하는 방법이나 generator를 사용해 데이터 증강시키는 방법을 고려해보긴 했지만, 갖고있는 데이터 자체가 깔끔한 편이 아니라고 생각해 데이터 증강기법을 사용했을 때 오히려 악영향이 더 클 것이라 판단하여 보류하였음. resnet을 사용하신 다른 수강생분들의 모델을 따와서 데이터를 넣어보았지만 동일하게 60%를 넘을수는 없었으므로.. 깔끔하게 포기함..! 이미지데이터를 어떻게 전처리해야할지 난감한 부분들이 너무 많았음.
