# 회고록
### 주말을 날린 나에게 바치는 추모문
모델 하이퍼파라미터 조정 이전에 데이터 전처리를 어떻게 하느냐에 따라서 점수가 크게 변화할거라고 가정하고, 데이터 전처리 중심으로 시작하였음. 수치형과 범주형데이터를 나누고 범주형('view', 'condition', 'grade')에는 get_dummies를 이용해 원핫인코딩을,불필요하다고 생각했던 컬럼들( 'zipcode', 'lat', 'long')을 삭제, IQR과 StandardScaler를 사용하여 데이터를 가꾸고 모델에 입력하였지만, 결과적으로 오히려 score는 40만~60만을 넘나들며 크게 상승해버렸다.  
전처리가 잘못되었다고 생각하여 Kaggle의 노트북 중 vote를 가장 많이 받은 분의 데이터 전처리부분을 살펴보며, 일부 차용하여 다시 진행하였지만, 결과는 동일했다. 어떤 부분이... 잘못되었는지 판단하기 이전에 제출기한을 지키기 위해 일단 전처리 부분은 노드의 궤를 그대로 수용하여 진행하고 모델 하이퍼파라미터 조정과 여러모델의 가중평균을 통해 11만 이하 score 달성을 제1목표로 변경하였다.

### 데이터 전처리 타임라인
1. price log화 누락
목적변수가 정규성을 띄지않는 상태에서 EDA 및 전처리를 진행하니 오히려 점수가 상승하는 효과를 보임. 데이터 분석을 시작할때 반드시 목적변수에 대한 분석부터 시작해야함을 깨달음.

2. 이상치 처리 및 scaler의 영향
일반적으로 이상치 처리와 StandardScaler를 사용했을 때 모델 향상에 유의미한 영향을 주었던 경험이 있는데, 이번에는 오히려 악영향을 주는 경우가 더 많았음. 어떠한 것이 원인인지는 ... 알 수 없었고 추측으로는 이상치들이 가중치 설정에 중요한 역할을 했을거라는 생각정도

3. 일부 컬럼 삭제 및 더미변수화
view, condition 컬럼의 더미변수화 정도는 현상유지가 가능했지만, grade를 더미변수화하니 오히려 모델성능이 떨어지는 모습을 보여줌. 범주형데이터라고 해서 모두 더미변수화 시키는건 안좋은 습관인 것을 알게됨. 더미변수의 영향으로 컬럼이 과하게 많아지는 것을 방지하기 위해서 일부 컬럼을 삭제하였으나, 동일하게 모델 성능이 하락함. lat 컬럼의 경우 다른 캐글러분들의 분석을 통해 유의미한 변수라는 것을 인지했지만, zipcode, sqft_living, sqft_lot 등의 컬럼이 어떤 이유로 설명력을 높여주는지 이해하지 못했음.

4. 데이터 전처리 포기와 데이터 분석이 우수한 캐글러 따라하기
결과적으로 노드에서 진행한 전처리가 가장 11만에 근접한 점수를 내어 이전에 진행한 모든 전처리를 삭제 후 우수 노트북의 분석방법론을 공부하는 정도로 그치기로 함.

### 하이퍼파라미터 조정
![image](https://user-images.githubusercontent.com/69811817/167563700-c5b1c6dd-059f-4a95-94eb-10d1210ddf01.png)
![image](https://user-images.githubusercontent.com/69811817/167563962-84e12270-7d04-441f-bff9-508b893ef378.png)
1. 단일 모델 선정후 그리드 서치의 하이퍼파라미터 최적화
4개의 모델 모두 11만점 후반~ 12만점 초반을 기록함. 특히 부스팅계열의 모델은 하이퍼파라미터 조정으로 유의미한 변화는 일어나지않음.
2. 복수의 모델 예측값을 임의의 비중으로 합치기
stack을 활용하여 복수의 기본모델로 성능향상을 노렸으나, 코드 구현의 어려움으로 생각을 전환하여 그리드 서치로 최적화한 모델들의 예측값을 가중평균하여 제출해봄. 단일 모델에 비해서 상대적으로 낮은 점수를 기록, 다만 2개 이상의 모델을 평균한 값은 오히려 점수가 높아지는 경향을 보임. 따라서 최대 2개로 제한하고 그리드서치에 걸리는 시간과 조합 시너지를 고려했을 때 ligtGBM과 XGBoost가 적합한 것으로 판단하였다.  
이후 모델 예측값의 가중치를 조절하며 가장 낮은 점수를 선정함.(위의 표를 기준으로 lightGBM이 가장 설명력이 높았던 점을 감안해 GBM의 가중을 점차 늘려감)

## 짧은 회고
데이터 전처리에 실패한 것이 너무 아쉬운 과제였음.
private or public score에 따라서 모델의 파라미터나 가중치를 조절하는 방법이 적절하지는 않았던 것 같음.(kaggle test 데이터에만 적합하게되는 모델일 가능성 有)
![image](https://user-images.githubusercontent.com/69811817/167566309-69199941-0028-44b2-91ba-3535ec14144d.png)

